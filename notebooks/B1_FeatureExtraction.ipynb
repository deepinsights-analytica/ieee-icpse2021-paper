{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:gray\">\n",
    "Copyright &copy; 2020-2021 by Fraunhofer-Gesellschaft. All rights reserved.<br>\n",
    "Fraunhofer Institute for Integrated Circuits IIS, Division Engineering of Adaptive Systems EAS<br>\n",
    "Zeunerstraße 38, 01069 Dresden, Germany\n",
    "</span>\n",
    "\n",
    "---\n",
    "\n",
    "## ESB - Energy Saving by Blockchain\n",
    "\n",
    "Eurostars – EXP 00119832 / EUS-2019113348\n",
    "\n",
    "---\n",
    "\n",
    "## Prediction of Energy Consumption for Variable Customer Portfolios Including Aleatoric Uncertainty Estimation\n",
    "\n",
    "*Oliver Mey, André Schneider, Olaf Enge-Rosenblatt, Yesnier Bravo, Pit Stenzel*\n",
    "\n",
    "The notebook is part of a paper submission contributed to the **10th International Conference on Power Science and Engineering (ICPSE 2021)** will be held on Oct. 21-23, 2021 in Yildiz Technical University, Istanbul, Turkey.\n",
    "\n",
    "---\n",
    "\n",
    "# B1: Feature Extraction\n",
    "\n",
    "This notebook loads the available datasets and extracts the features needed as input for the prediction models for a pre-defined date (*2019-02-02*) and a customer (*#20*). The feature extraction uses pre-train\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"color:gray\">\n",
    "Version 0.3.1 (August 2, 2021)<br>\n",
    "Authors: Oliver Mey, André Schneider (Fraunhofer IIS)<br>\n",
    "</span>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays as hd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(16, 6)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..'\n",
    "timezone = 'Europe/Madrid'\n",
    "date = '2019-02-02'\n",
    "customer = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_UTC(data, tz=timezone):\n",
    "    try:\n",
    "        data.index = data.index.tz_localize(tz=tz, ambiguous='infer').tz_convert(tz='UTC')\n",
    "    except:\n",
    "        pass\n",
    "    return\n",
    "\n",
    "def crop(data):\n",
    "    hour_index = data.index.hour\n",
    "    t0 = data[hour_index==0].head(1).index\n",
    "    tn = data[hour_index==23].tail(1).index\n",
    "    data.drop(data.loc[data.index < t0[0]].index, inplace=True)\n",
    "    data.drop(data.loc[data.index > tn[0]].index, inplace=True)\n",
    "    return\n",
    "\n",
    "def time_from_to(date, t, tz=timezone):\n",
    "    t0_ = pd.Timestamp(date, tz=tz)+pd.Timedelta(days=t[0])\n",
    "    tn_ = pd.Timestamp(date, tz=tz)+pd.Timedelta(days=t[1])+pd.Timedelta(hours=23)\n",
    "    return slice(t0_, tn_)\n",
    "\n",
    "def day_from_to(date, t, tz=timezone):\n",
    "    t0_ = pd.Timestamp(date)+pd.Timedelta(days=t[0])\n",
    "    tn_ = pd.Timestamp(date)+pd.Timedelta(days=t[1])\n",
    "    return slice(t0_, tn_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \n",
    "    def __init__(self, data_path, model_path):\n",
    "        self.data_path = data_path\n",
    "        self.model_path = model_path\n",
    "        self.categories = ['consumption', 'weather', 'profiles']\n",
    "        self.scaler_names = ['scaler_consumptions', 'scaler_consumptions_daily_mean',\n",
    "                             'scaler_weather_daily_mean', 'scaler_day_of_month', 'scaler_month',\n",
    "                             'scaler_weather_forecast']\n",
    "        self.files = [self.data_path + '/' + '20201015_' + name + '.xlsx' for name in self.categories]\n",
    "        return\n",
    "    \n",
    "    def load_metadata(self):\n",
    "        customers = pd.read_excel(self.files[self.categories.index('profiles')])\n",
    "        customers.columns = ['customer', 'profile']\n",
    "        profiles = pd.DataFrame(customers['profile'].unique(), columns=['profile'])\n",
    "        holidays = hd.ES(years=list(range(2010, 2021)), prov=\"MD\")\n",
    "        return customers, profiles, holidays\n",
    "    \n",
    "    def load_data(self):\n",
    "        consumptions = pd.read_excel(self.files[self.categories.index('consumption')], parse_dates=[0], index_col=0)\n",
    "        consumptions.columns = pd.DataFrame(consumptions.columns, columns=['customer']).index\n",
    "        consumptions.index.name = 'time'\n",
    "        to_UTC(consumptions)\n",
    "        crop(consumptions)\n",
    "        weather = pd.read_excel(self.files[self.categories.index('weather')], parse_dates=[0], index_col=0)\n",
    "        weather.columns = consumptions.columns\n",
    "        weather.index.name = 'time'\n",
    "        to_UTC(weather)\n",
    "        crop(weather)\n",
    "        return consumptions, weather\n",
    "    \n",
    "    def load_scalers(self):\n",
    "        scalers = [joblib.load(self.model_path + '/' + name) for name in self.scaler_names]\n",
    "        scalers = dict(zip(self.scaler_names, scalers))\n",
    "        scale = scalers['scaler_consumptions'].scale_\n",
    "        offset = scalers['scaler_consumptions'].mean_\n",
    "        return scalers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \n",
    "    def __init__(self, properties):\n",
    "        self.t_consumption_daily = properties.get('t_consumption_daily', [-13, -1])\n",
    "        self.t_consumption_hourly = properties.get('t_consumption_hourly', [-2, -1])\n",
    "        self.t_weather_daily = properties.get('t_weather_daily', [-2, -0])\n",
    "        self.t_weather_hourly = properties.get('t_weather_hourly', [-2, -0])\n",
    "        \n",
    "        scalers = properties.get('scalers')\n",
    "        self.scaler_consumption = scalers['scaler_consumptions']\n",
    "        self.scaler_weather_forecast = scalers['scaler_weather_forecast']\n",
    "        self.scaler_day_of_month = scalers['scaler_day_of_month']\n",
    "        self.scaler_month = scalers['scaler_month']\n",
    "        self.encoder = properties.get('encoder')\n",
    "        return\n",
    "\n",
    "    def get_days(self, dates, holidays):\n",
    "        days = pd.DataFrame(pd.to_datetime(dates.date), index=dates, columns=['date'])\n",
    "        days['day_of_week'] = list(days.index.dayofweek)\n",
    "        days['day_of_month'] = list(days.index.day)\n",
    "        days['month'] = list(days.index.month)\n",
    "        days['day_category'] = days['day_of_week'].replace({0:0,1:1,2:1,3:1,4:2,5:3,6:4})\n",
    "        days.loc[days['date'].apply(lambda d: d in holidays), 'day_category'] = 4\n",
    "        days = days.groupby(['date']).first()\n",
    "        return days\n",
    "        \n",
    "    def extract(self, date, customer, consumptions, weathers, holidays):\n",
    "        days = self.get_days(consumptions.index, holidays)\n",
    "        consumptions_daily_mean = pd.DataFrame(consumptions.groupby(consumptions.index.date).mean(), \n",
    "                                               index=days.index)\n",
    "        weather_daily_mean = pd.DataFrame(weather.groupby(weather.index.date).mean(), \n",
    "                                          index=days.index)\n",
    "        X1 = consumptions.loc[time_from_to(date, self.t_consumption_hourly),customer].values\n",
    "        X1 = self.scaler_consumption.transform(np.array(X1).reshape(-1,1)).reshape(-1)\n",
    "        X2 = weather.loc[time_from_to(date, self.t_weather_hourly),customer].values\n",
    "        X2 = self.scaler_weather_forecast.transform(np.array(X2).reshape(3,24)).reshape(-1)\n",
    "        X3 = days.loc[pd.Timestamp(date),'day_of_month']\n",
    "        X3 = self.scaler_day_of_month.transform(np.array([X3]).reshape(-1,1))[0][0]\n",
    "        X4 = days.loc[pd.Timestamp(date),'month']\n",
    "        X4 = self.scaler_month.transform(np.array([X4]).reshape(-1,1))[0][0]\n",
    "        X5 = days.loc[pd.Timestamp(date),'day_category']\n",
    "        X5 = self.encoder.transform(np.array(X5).reshape(1, -1)).reshape(-1)\n",
    "        Xa = np.concatenate([X1, X2, [X3], [X4], X5]).reshape(1,-1)\n",
    "        X1 = consumptions_daily_mean.loc[day_from_to(date, self.t_consumption_daily), customer].values\n",
    "        X2 = weather_daily_mean.loc[day_from_to(date, self.t_weather_daily), customer].values\n",
    "        X3 = self.encoder.transform(np.array([days.loc[pd.Timestamp(date), 'day_category'].astype(np.int32)]).reshape(1,-1))\n",
    "        Xb = np.concatenate([X1, X2, X3[0]]).reshape(1,-1)\n",
    "        return [Xa, Xb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(sparse=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(path + '/data', path + '/models')\n",
    "consumptions, weather = loader.load_data()\n",
    "customers, profiles, holidays = loader.load_metadata()\n",
    "scalers = loader.load_scalers()\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder.fit(np.arange(5).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {\n",
    "    't_consumption_daily': [-13, -1],\n",
    "    't_consumption_hourly': [-2, -1],\n",
    "    't_weather_daily': [-2, 0],\n",
    "    't_weather_hourly': [-2, 0],\n",
    "    'scalers': scalers,\n",
    "    'encoder': encoder\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FeatureExtractor(properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extractor.extract(date, customer, consumptions, weather, holidays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: 2 Feature Vectors Xa, Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa, Xb = features[0], features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 127), (1, 21))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xa.shape, Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.33132207e+00  2.90308340e+00  2.72049157e+00  2.58586877e+00\n",
      "   2.47755158e+00  2.53016279e+00  2.37387655e+00  2.09689402e+00\n",
      "   1.53983418e+00  3.44621675e+00  2.68180685e+00  9.42842048e+00\n",
      "   1.02005673e+01  8.28180564e+00  9.73016123e+00  1.57680709e+01\n",
      "   1.31344158e+01  1.15158475e+01  1.15065632e+01  9.89882657e+00\n",
      "   9.27522902e+00  7.93673802e+00  9.24892342e+00  9.98857510e+00\n",
      "   8.96110917e+00  5.58470758e+00  4.32203861e+00  3.12281256e+00\n",
      "   2.42184560e+00  2.27948586e+00  2.70347029e+00  2.74370239e+00\n",
      "   2.89225168e+00  5.34331498e+00  8.30965863e+00  8.21062577e+00\n",
      "   1.19382845e+01  9.47948430e+00  1.07808380e+01  1.38493093e+01\n",
      "   1.26423463e+01  1.15220370e+01  1.05146872e+01  8.03577088e+00\n",
      "   9.29998724e+00  9.76110900e+00  1.11754220e+01  1.02686524e+01\n",
      "  -2.70649044e-02  1.56157472e-02  5.37974926e-02  9.20993149e-02\n",
      "   1.36802432e-01  1.60638568e-01  1.82433798e-01  1.56729281e-01\n",
      "  -8.99169761e-03 -1.68757540e-01 -3.83298186e-01 -5.68986924e-01\n",
      "  -7.48309826e-01 -8.36426911e-01 -9.09749517e-01 -9.77237498e-01\n",
      "  -9.03590003e-01 -8.20755476e-01 -7.36934645e-01 -6.92891840e-01\n",
      "  -6.38072348e-01 -5.72368719e-01 -5.64699218e-01 -5.80765191e-01\n",
      "  -5.91795751e-01 -6.04640639e-01 -6.20453712e-01 -6.34552253e-01\n",
      "  -6.39819553e-01 -6.56292808e-01 -6.73379687e-01 -7.81686526e-01\n",
      "  -9.70280130e-01 -1.13409353e+00 -1.27019971e+00 -1.39241562e+00\n",
      "  -1.49720974e+00 -1.43456450e+00 -1.38743855e+00 -1.33898492e+00\n",
      "  -1.23664947e+00 -1.14463424e+00 -1.05007629e+00 -1.00297794e+00\n",
      "  -9.56938287e-01 -9.00671004e-01 -8.46441435e-01 -8.04371538e-01\n",
      "  -7.54698880e-01 -7.20840570e-01 -6.86773502e-01 -6.50383442e-01\n",
      "  -6.28679484e-01 -6.21462401e-01 -6.12025411e-01 -6.61675979e-01\n",
      "  -7.99862387e-01 -9.15284035e-01 -1.03806844e+00 -1.14441446e+00\n",
      "  -1.23517565e+00 -1.23313513e+00 -1.23530828e+00 -1.23391306e+00\n",
      "  -1.10963527e+00 -9.91071030e-01 -8.70157188e-01 -7.60893177e-01\n",
      "  -6.40894170e-01 -5.06998795e-01 -4.27635437e-01 -3.75664197e-01\n",
      "  -1.55939125e+00 -1.31110185e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(Xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.12908333  5.2375      5.686       6.12191667  5.17904167  3.348\n",
      "   3.69833333  3.639125    4.56720833  5.32829167  5.187625    5.02570833\n",
      "   5.46291667 14.79333333 11.10458333 12.29333333  0.          0.\n",
      "   0.          1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
